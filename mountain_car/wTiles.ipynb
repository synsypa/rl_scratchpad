{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from mountain_car import MountainCar\n",
    "from tilecoding import TileCoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_per_dim = [8, 8]\n",
    "pos_lims = (env.observation_space.low[0], env.observation_space.high[0])\n",
    "spd_lims = (env.observation_space.low[1], env.observation_space.high[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = [pos_lims, spd_lims]\n",
    "n_tilings = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TileCoder(tiles_per_dim, lims, n_tilings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39, 120, 201, 283])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[env.reset()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtest= np.zeros((T.n_tiles, env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([qtest[T[env.reset()]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtest[T[env.reset()]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtest[T[env.reset()], 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(qtest[T[env.reset()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "c = [7,8,9]\n",
    "\n",
    "abc = np.array([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = T[env.reset()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtest[a, 1] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 10.,  0.],\n",
       "       [ 0., 10.,  0.],\n",
       "       [ 0., 10.,  0.],\n",
       "       [ 0., 10.,  0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtest[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sum(qtest[a])/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(qtest[a, 1])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-85-d3715ab97b8c>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-85-d3715ab97b8c>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    lims = [(self.env.observation_space.low[0], self.env.observation_space.high[0]), /\u001b[0m\n\u001b[0m                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class MountainCarTiles:\n",
    "    def __init__(self, env, algo, alpha, gamma, epsilon, tiles_per_dim, n_tilings):\n",
    "        self.env = env\n",
    "        self.algo = algo\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.tiles_per_dim = tiles_per_dim\n",
    "        self.n_tilings = n_tilings\n",
    "        lims = [(self.env.observation_space.low[0], self.env.observation_space.high[0]), /\n",
    "                (self.env.observation_space.low[1], self.env.observation_space.high[1])]\n",
    "        self.T = TileCoder(self.tiles_per_dim, lims, self.n_tilings)\n",
    "        self.Q = np.zeros((self.T.n_tiles, self.env.action_space.n))\n",
    "        self.ep_reward = []\n",
    "        self.reward_list = []\n",
    "        self.episodes = 0\n",
    "    \n",
    "    def _discretize_state(self, state):\n",
    "        return T[state]\n",
    "    \n",
    "    def _get_mean_tile_Q(self, discrete_state):\n",
    "        return sum(self.Q[discrete_state])/self.n_tilings\n",
    "        \n",
    "    def _epsilon_greed(self, discrete_state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, self.env.action_space.n-1)\n",
    "        else:\n",
    "            # use mean of states' rewards as reward\n",
    "            return np.argmax(self._get_mean_tile_Q(discrete_state))\n",
    "    \n",
    "    def _get_expected_reward(self, discrete_state):\n",
    "        actions = [i for i in range(self.env.action_space.n)]\n",
    "        # Find greedy action, (1-ep)*greedy reward\n",
    "        greedy_action = np.argmax(self._get_mean_tile_Q(discrete_state))\n",
    "        greedy_reward = (1-self.epsilon) * self._get_mean_tile_Q(discrete_state)[greedy_action]\n",
    "        # other actions, ep/n_actions * reward\n",
    "        other_rewards = 0\n",
    "        for a in actions:\n",
    "            other_rewards += (self.epsilon/len(actions)) * self._get_mean_tile_Q(discrete_state)[a]\n",
    "        return greedy_reward + other_rewards\n",
    "    \n",
    "    def _calc_avg_reward(self):\n",
    "        avg_ep_reward = np.mean(self.ep_reward)\n",
    "        self.reward_list.append(avg_ep_reward)\n",
    "        self.ep_reward = []\n",
    "        return(avg_ep_reward)\n",
    "    \n",
    "    def run_episode(self, decay, render = False):\n",
    "        if self.episodes % 500 == 0 or render:\n",
    "            print(f'Running episode {self.episodes} using {self.algo}, epsilon={round(self.epsilon,5)}, alpha={self.alpha}, discount={self.gamma}')\n",
    "        end = False\n",
    "        total_reward, reward = 0,0\n",
    "        # Initial State\n",
    "        S = self.env.reset()\n",
    "        # Discreize State\n",
    "        S_dis = self._discretize_state(S)\n",
    "        while not end:\n",
    "            if render:\n",
    "                env.render()\n",
    "                \n",
    "            action = self._epsilon_greed(S_dis)\n",
    "            S_next, reward, end, _ = self.env.step(action)\n",
    "            S_dis_next = self._discretize_state(S_next)\n",
    "            \n",
    "            # If end of episode\n",
    "            if end and S_next[0] >= 0.5:\n",
    "                self.Q[S_dis, action] = reward\n",
    "                \n",
    "            # otherwise update according to chosen algorithm\n",
    "            else:\n",
    "                if self.algo == 'q':\n",
    "                    next_reward = np.max(self._get_mean_tile_Q(S_dis_next))\n",
    "                elif self.algo == 'expected_sarsa':\n",
    "                    next_reward = self._get_expected_reward(S_dis_next)\n",
    "                elif self.algo == 'sarsa':\n",
    "                    next_reward = self._get_mean_tile_Q(S_dis_next)[self._epsilon_greed(S_dis_next)]\n",
    "                    \n",
    "                delta = self.alpha * (reward + (self.gamma * next_reward) - self._get_mean_tile_Q(S_dis)[action])\n",
    "                self._get_mean_tile_Q(S_dis_next)[action] += delta\n",
    "                \n",
    "            S_dis = S_dis_next\n",
    "            total_reward += reward\n",
    "            \n",
    "        if render:\n",
    "            if (S_next[0] >= 0.5):\n",
    "                print('Success :)')\n",
    "            else: \n",
    "                print('Failure :(')\n",
    "            time.sleep(1)\n",
    "            \n",
    "        self.ep_reward.append(total_reward)\n",
    "        self.episodes += 1\n",
    "        self.epsilon -= decay\n",
    "        if self.episodes % 100 == 0:\n",
    "            avg_reward = self._calc_avg_reward()\n",
    "            if self.episodes % 500 == 0:\n",
    "                print(f'Avg Reward Over Last 100 Episodes = {avg_reward}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
